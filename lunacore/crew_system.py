"""
LunaCore CrewAI System
Multi-agent code generation with CrewAI framework
"""

import os
import re
import ast
import time
from pathlib import Path
from typing import List, Dict, Optional
from dotenv import load_dotenv

# CrewAI imports
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool

# LangChain imports
from langchain_community.llms import Ollama
from langchain_openai import ChatOpenAI

# Load environment variables
load_dotenv()

class LunaCrewSystem:
    """
    Syst√®me multi-agents avec CrewAI pour g√©n√©ration de projets complets
    
    Architecture:
    - OpenAI GPT-4 : Superviseur/Architecte (planification, guidance)
    - Llama3.1:8b : D√©veloppeurs sp√©cialis√©s (impl√©mentation)
    """
    
    def __init__(self):
        """Initialise le syst√®me CrewAI avec tous les agents"""
        self.llama_model = "llama3.1:8b"
        self.openai_model = "gpt-4o-mini"
        
        # Initialiser les LLMs
        self._init_llms()
        
        # Cr√©er les outils
        self.tools = self._create_tools()
        
        # Cr√©er les agents
        self.agents = self._create_agents()
        
        print(f"‚úÖ LunaCrewSystem initialis√© avec {len(self.agents)} agents")
    
    def _init_llms(self):
        """Initialise les mod√®les de langage"""
        try:
            # Ollama pour Llama3.1:8b
            ollama_base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
            self.llama = Ollama(
                model=self.llama_model,
                base_url=ollama_base_url,
                temperature=0.7
            )
            self.llama_available = True
            print(f"‚úÖ Llama3.1:8b connect√© via {ollama_base_url}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Ollama non disponible: {e}")
            # Fallback vers OpenAI
            self.llama = None
            self.llama_available = False
            
        try:
            # OpenAI pour supervision
            openai_key = os.getenv("OPENAI_API_KEY")
            if not openai_key or openai_key == "your_openai_api_key_here":
                raise ValueError("OPENAI_API_KEY non configur√©e dans .env")
            
            self.openai = ChatOpenAI(
                model=self.openai_model,
                temperature=0.2,
                api_key=openai_key
            )
            print(f"‚úÖ OpenAI {self.openai_model} connect√©")
            
            # Si Ollama n'est pas disponible, utilise OpenAI pour tout
            if not self.llama_available:
                self.llama = ChatOpenAI(
                    model="gpt-4o-mini",
                    temperature=0.5,
                    api_key=openai_key
                )
                print("üîÑ Utilisation d'OpenAI comme fallback pour le d√©veloppement")
            
        except Exception as e:
            print(f"‚ùå Erreur d'initialisation OpenAI: {e}")
            raise
    
    def _create_tools(self):
        """Cr√©e les outils personnalis√©s pour les agents"""
        
        @tool
        def write_file_tool(filename: str, content: str) -> str:
            """√âcrit du contenu dans un fichier"""
            try:
                # Cr√©er le r√©pertoire si n√©cessaire
                output_dir = Path("sandbox/crew_output")
                output_dir.mkdir(parents=True, exist_ok=True)
                
                file_path = output_dir / filename
                file_path.write_text(content, encoding='utf-8')
                
                lines = len(content.splitlines())
                return f"‚úÖ Fichier {filename} cr√©√© ({lines} lignes)"
            except Exception as e:
                return f"‚ùå Erreur lors de l'√©criture de {filename}: {e}"
        
        @tool
        def validate_python_syntax(code: str) -> str:
            """Valide la syntaxe Python d'un code"""
            try:
                ast.parse(code)
                return "‚úÖ Syntaxe Python valide"
            except SyntaxError as e:
                return f"‚ùå Erreur de syntaxe: {e.msg} (ligne {e.lineno})"
        
        @tool
        def ask_supervisor_help(problem: str, context: str) -> str:
            """Demande de l'aide au superviseur OpenAI"""
            try:
                prompt = f"""
                Un agent d√©veloppeur a besoin d'aide:
                
                PROBL√àME: {problem}
                CONTEXTE: {context}
                
                Fournis une guidance claire et actionnable (pas de code, juste l'approche/strat√©gie).
                Sois concis et pratique.
                """
                
                response = self.openai.invoke(prompt)
                return f"üí° Conseil du superviseur: {response.content}"
            except Exception as e:
                return f"‚ùå Erreur de communication avec le superviseur: {e}"
        
        return [write_file_tool, validate_python_syntax, ask_supervisor_help]
    
    def _create_agents(self) -> Dict[str, Agent]:
        """Cr√©e tous les agents du syst√®me"""
        agents = {}
        
        # üß† SUPERVISEUR (OpenAI) - Architecture et guidance uniquement
        agents['supervisor'] = Agent(
            role="Architecte et Superviseur Senior",
            goal="Concevoir l'architecture du projet et guider les d√©veloppeurs",
            backstory="""
            Tu es un architecte logiciel senior avec 15+ ans d'exp√©rience.
            Tu NE CODES PAS - tu con√ßois, planifies et guides les autres agents.
            Tu interviens pour d√©bloquer les situations complexes.
            """,
            llm=self.openai,
            verbose=True,
            allow_delegation=True,
            max_iter=2
        )
        
        # üíª D√âVELOPPEUR PRINCIPAL (Llama) - Impl√©mentation compl√®te
        agents['main_developer'] = Agent(
            role="D√©veloppeur Full-Stack Principal",
            goal="Impl√©menter le code principal du projet de A √† Z",
            backstory="""
            Tu es un d√©veloppeur expert qui ma√Ætrise Python, FastAPI, Streamlit, etc.
            Tu √©cris du code propre, fonctionnel et bien structur√©.
            Tu impl√©mentes les fichiers principaux (main.py, app.py, etc.).
            """,
            llm=self.llama,
            tools=self.tools,
            verbose=True,
            max_iter=4,
            memory=True
        )
        
        # üîß D√âVELOPPEUR BACKEND (Llama) - APIs et services
        agents['backend_developer'] = Agent(
            role="D√©veloppeur Backend Sp√©cialis√©",
            goal="Cr√©er les APIs, endpoints et services backend",
            backstory="""
            Tu es sp√©cialis√© en d√©veloppement backend.
            Tu cr√©es les APIs REST, g√®res les bases de donn√©es et les services.
            Tu ma√Ætrises FastAPI, Flask, SQLAlchemy, etc.
            """,
            llm=self.llama,
            tools=self.tools,
            verbose=True,
            max_iter=3
        )
        
        # üß™ TESTEUR (Llama) - Tests automatis√©s
        agents['tester'] = Agent(
            role="Ing√©nieur QA et Tests",
            goal="Cr√©er une suite de tests compl√®te et robuste",
            backstory="""
            Tu es expert en tests automatis√©s avec pytest.
            Tu cr√©es des tests unitaires, d'int√©gration et fonctionnels.
            Tu assures la qualit√© et la fiabilit√© du code.
            """,
            llm=self.llama,
            tools=self.tools,
            verbose=True,
            max_iter=2
        )
        
        # üìö DOCUMENTALISTE (Llama) - Documentation technique
        agents['documenter'] = Agent(
            role="R√©dacteur Technique",
            goal="Cr√©er une documentation claire et compl√®te",
            backstory="""
            Tu r√©diges des documentations techniques excellentes.
            Tu cr√©es des README, docstrings et guides d'utilisation.
            Tu expliques clairement comment utiliser le projet.
            """,
            llm=self.llama,
            tools=self.tools,
            verbose=True,
            max_iter=2
        )
        
        return agents
    
    def generate_project(self, brief: str, template: str = "fastapi") -> Dict:
        """
        G√©n√®re un projet complet avec le crew multi-agents
        
        Args:
            brief: Description du projet √† g√©n√©rer
            template: Type de template (fastapi, streamlit, cli, etc.)
        
        Returns:
            Dictionnaire avec les r√©sultats de g√©n√©ration
        """
        print(f"üöÄ G√©n√©ration du projet: {brief[:50]}...")
        print(f"üìã Template: {template}")
        
        start_time = time.time()
        
        try:
            # Cr√©er les t√¢ches
            tasks = self._create_project_tasks(brief, template)
            
            # Cr√©er le crew avec processus hi√©rarchique
            crew = Crew(
                agents=list(self.agents.values()),
                tasks=tasks,
                process=Process.hierarchical,
                manager_llm=self.openai,  # OpenAI g√®re le processus
                verbose=True,
                memory=True,
                max_rpm=10
            )
            
            # Ex√©cuter la g√©n√©ration
            result = crew.kickoff(inputs={
                "brief": brief,
                "template": template,
                "project_name": self._extract_project_name(brief)
            })
            
            # Analyser les r√©sultats
            execution_time = time.time() - start_time
            generated_files = self._scan_output_directory()
            
            return {
                "status": "success",
                "execution_time": round(execution_time, 2),
                "files": generated_files,
                "agents_count": len(self.agents),
                "tasks_count": len(tasks),
                "result": str(result),
                "output_directory": "sandbox/crew_output"
            }
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration: {e}")
            return {
                "status": "error",
                "error": str(e),
                "execution_time": time.time() - start_time
            }
    
    def _create_project_tasks(self, brief: str, template: str) -> List[Task]:
        """Cr√©e les t√¢ches pour le projet"""
        tasks = []
        
        # T√ÇCHE 1: Architecture (Superviseur OpenAI)
        tasks.append(Task(
            description=f"""
            Analyse le brief et con√ßois l'architecture compl√®te:
            
            BRIEF: {brief}
            TEMPLATE: {template}
            
            D√©finis:
            1. Structure des fichiers et dossiers
            2. Composants principaux n√©cessaires
            3. D√©pendances et technologies
            4. Plan d'impl√©mentation √©tape par √©tape
            
            NE CODE PAS - fournis uniquement le plan architectural.
            """,
            agent=self.agents['supervisor'],
            expected_output="Plan d'architecture d√©taill√© avec structure de fichiers"
        ))
        
        # T√ÇCHE 2: Impl√©mentation principale (Llama)
        tasks.append(Task(
            description=f"""
            Impl√©mente le fichier principal du projet selon l'architecture.
            
            Cr√©e le fichier principal (main.py, app.py selon le template) avec:
            - Code complet et fonctionnel
            - Imports et d√©pendances
            - Structure de base du projet
            - Configuration n√©cessaire
            
            Template: {template}
            
            Utilise l'outil write_file_tool pour cr√©er le fichier.
            """,
            agent=self.agents['main_developer'],
            expected_output="Fichier principal impl√©ment√©",
            context=[tasks[0]]
        ))
        
        # T√ÇCHE 3: Backend/API (si applicable)
        if template in ["fastapi", "flask", "django"]:
            tasks.append(Task(
                description="""
                Impl√©mente les composants backend selon l'architecture:
                - Endpoints API n√©cessaires
                - Mod√®les de donn√©es
                - Middleware et configuration
                - Gestion des erreurs
                
                Utilise write_file_tool pour cr√©er les fichiers backend.
                """,
                agent=self.agents['backend_developer'],
                expected_output="Composants backend impl√©ment√©s",
                context=[tasks[0]]
            ))
        
        # T√ÇCHE 4: Tests
        tasks.append(Task(
            description="""
            Cr√©e une suite de tests pour le projet:
            - Tests unitaires des fonctions principales
            - Tests d'int√©gration si n√©cessaire
            - Fichiers de test avec pytest
            - Configuration de test
            
            Utilise write_file_tool pour cr√©er test_*.py
            """,
            agent=self.agents['tester'],
            expected_output="Suite de tests compl√®te",
            context=tasks[-2:]
        ))
        
        # T√ÇCHE 5: Documentation
        tasks.append(Task(
            description="""
            Cr√©e la documentation compl√®te:
            - requirements.txt avec toutes les d√©pendances
            - README.md avec instructions d'installation/utilisation
            - Docstrings dans le code si n√©cessaire
            - Exemples d'utilisation
            
            Utilise write_file_tool pour cr√©er la documentation.
            """,
            agent=self.agents['documenter'],
            expected_output="Documentation compl√®te",
            context=tasks
        ))
        
        return tasks
    
    def _extract_project_name(self, brief: str) -> str:
        """Extrait un nom de projet du brief"""
        # Nettoie et extrait les premiers mots significatifs
        words = re.findall(r'\b[a-zA-Z]{3,}\b', brief.lower())
        project_name = "_".join(words[:2]) if len(words) >= 2 else "lunacore_project"
        return project_name
    
    def _scan_output_directory(self) -> Dict[str, str]:
        """Scanne le r√©pertoire de sortie pour les fichiers g√©n√©r√©s"""
        output_dir = Path("sandbox/crew_output")
        files = {}
        
        if output_dir.exists():
            for file_path in output_dir.rglob("*"):
                if file_path.is_file():
                    try:
                        content = file_path.read_text(encoding='utf-8')
                        relative_path = str(file_path.relative_to(output_dir))
                        files[relative_path] = content
                    except Exception as e:
                        files[str(file_path.name)] = f"Erreur de lecture: {e}"
        
        return files

    def test_agents(self) -> Dict:
        """Test rapide de tous les agents"""
        try:
            return {
                "status": "success",
                "agents_count": len(self.agents),
                "llm_backend": "Llama3.1:8b" if self.llama_available else "OpenAI",
                "tools_count": len(self.tools),
                "agents": list(self.agents.keys())
            }
        except Exception as e:
            return {
                "status": "error", 
                "error": str(e)
            }

# Instance globale pour utilisation facile
luna_crew = None

def get_crew_system() -> LunaCrewSystem:
    """Retourne l'instance globale du syst√®me CrewAI"""
    global luna_crew
    if luna_crew is None:
        luna_crew = LunaCrewSystem()
    return luna_crew
