"""
LunaCore CrewAI System
Multi-agent code generation with CrewAI framework
"""

import os
import re
import ast
import time
from pathlib import Path
from typing import List, Dict, Optional
from dotenv import load_dotenv

# Import du module de journalisation am√©lior√©
from lunacore.logger import info, warning, error, success, get_logger

# Import du gestionnaire d'erreurs
from lunacore.error_handler import (
    ErrorContext, safe_execute, with_timeout, handle_llm_error,
    LunaError, AgentError, LLMError, TimeoutError
)

# CrewAI imports
from crewai import Agent, Task, Crew, Process, LLM
from crewai.tools import tool

# Import des tools runtime
from lunacore.tools_runtime import make_write_file_tool, validate_python_syntax

# OpenAI client pour fallback
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

# Load environment variables
load_dotenv()

class LunaCrewSystem:
    """
    Syst√®me multi-agents avec CrewAI pour g√©n√©ration de projets complets
    
    Architecture:
    - OpenAI GPT-4 : Superviseur/Architecte (planification, guidance)
    - Llama3.1:8b : D√©veloppeurs sp√©cialis√©s (impl√©mentation)
    """
    
    def __init__(self):
        """Initialise le syst√®me CrewAI avec tous les agents"""
        self.llama_model = "llama3.1:8b"
        self.openai_model = "gpt-4o-mini"
        
        # R√©cup√©rer le logger pour tracking des agents
        self.logger = get_logger()
        
        # Initialiser les LLMs
        self._init_llms()
        
        # Variable pour stocker le dossier du projet courant
        self.current_project_folder = None
        
        # Cr√©er les agents (sans tools pour l'instant)
        self.agents = self._create_agents()
        
        success(f"LunaCrewSystem initialis√© avec {len(self.agents)} agents", "system")
    
    def _init_llms(self):
        """Initialise les mod√®les de langage avec CrewAI LLM natifs"""
        try:
            # Initialiser OpenAI avec CrewAI LLM
            openai_key = os.getenv("OPENAI_API_KEY")
            if not openai_key or openai_key == "your_openai_api_key_here":
                raise ValueError("OPENAI_API_KEY non configur√©e dans .env")
            
            self.openai = LLM(model="openai/gpt-4o-mini")
            print(f"‚úÖ OpenAI gpt-4o-mini connect√© (CrewAI LLM)")
            
            # Initialiser client OpenAI direct pour fallback tools
            if OpenAI:
                self.openai_client = OpenAI(api_key=openai_key)
            else:
                self.openai_client = None
            
            # Test Ollama
            try:
                ollama_base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
                self.llama = LLM(
                    model="ollama/llama3.1:8b", 
                    base_url=ollama_base_url
                )
                # Test rapide
                test_response = "OK"  # Pas de test real pour √©viter les timeouts
                self.llama_available = True
                print(f"‚úÖ Ollama llama3.1:8b connect√© (CrewAI LLM)")
                
            except Exception as e:
                print(f"‚ö†Ô∏è Ollama non disponible: {e}")
                self.llama = self.openai  # Fallback vers OpenAI
                self.llama_available = False
                print("üîÑ Utilisation d'OpenAI comme fallback pour le d√©veloppement")
                
        except Exception as e:
            print(f"‚ùå Erreur d'initialisation LLM: {e}")
            raise
    def _create_agents(self) -> Dict[str, Agent]:
        """Cr√©e les 3 agents essentiels selon les sp√©cifications LunaCore refactoris√©es"""
        agents = {}
        
        # SUPERVISEUR - Architecte et Planificateur
        agents['supervisor'] = Agent(
            role="Superviseur",
            goal="√âlaborer un plan ex√©cutable, figer les interfaces, d√©couper le travail.",
            backstory="Architecte senior, rigoureux, privil√©gie robustesse et lisibilit√©.",
            llm=self.openai,  # Assignation directe OpenAI pour superviseur
            tools=[],  # Tools seront assign√©s dans generate_project
            allow_delegation=False,
            verbose=True,
            max_iter=3,
        )
        
        # D√âVELOPPEUR - Code et impl√©mentation 
        agents['developer'] = Agent(
            role="D√©veloppeur",
            goal="Impl√©menter tout le code selon plan.json sans d√©vier du contrat.",
            backstory="Ing√©nieur fullstack, TDD, docstrings, type hints, code clair.",
            llm=self.llama,  # Assignation directe Llama pour d√©veloppeur
            tools=[],  # Tools seront assign√©s dans generate_project
            allow_delegation=False,
            verbose=True,
            max_iter=4,
        )
        
        # TESTEUR - Tests et qualit√©
        agents['tester'] = Agent(
            role="Testeur",
            goal="G√©n√©rer tests Pytest, smoke tests, README d'ex√©cution.",
            backstory="Test d'abord, coverage et cas limites.",
            llm=self.llama,  # Assignation directe Llama pour testeur
            tools=[],  # Tools seront assign√©s dans generate_project
            allow_delegation=False,
            verbose=True,
            max_iter=3,
        )
        
        return agents
    
    def test_agents(self) -> Dict:
        """V√©rifie que chaque agent peut r√©pondre √† un prompt minimal via son LLM."""
        from time import time as _now
        results = {
            'status': 'ok',
            'agents_count': len(self.agents),
            'agent_tests': {},
            'llm_backend': {
                'model': os.getenv("LUNACORE_PLANNER_MODEL", "gpt-4o-mini"),
                'ollama_available': self.llama_available,
            },
        }
        test_prompt = "R√©ponds simplement: OK."
        for agent_name, agent in self.agents.items():
            start = _now()
            try:
                messages = [{"role": "user", "content": test_prompt}]
                # CrewAI LLM wrapper -> .call(messages)
                _ = safe_execute(
                    agent.llm.call,
                    messages,
                    fallback="(pas de r√©ponse)",
                    error_msg=f"test {agent_name}",
                )
                duration = _now() - start
                self.logger.log_agent(agent_name, "test_connection", "success", duration)
                results['agent_tests'][agent_name] = {'status': 'success', 'duration': duration}
            except Exception as e:
                duration = _now() - start
                self.logger.log_agent(agent_name, "test_connection", "failed", duration)
                results['agent_tests'][agent_name] = {'status': 'failed', 'duration': duration, 'error': str(e)}
        if any(t['status'] == 'failed' for t in results['agent_tests'].values()):
            results['status'] = 'partial'
        return results
    
    def generate_project(self, brief: str, template: str = "fastapi") -> Dict:
        """
        G√©n√®re un projet complet avec le crew multi-agents et tools runtime
        
        Args:
            brief: Description du projet √† g√©n√©rer
            template: Type de template (fastapi, streamlit, cli, etc.)
        
        Returns:
            Dictionnaire avec les r√©sultats de g√©n√©ration
        """
        info(f"üöÄ G√©n√©ration du projet: {brief[:50]}...", "generation")
        info(f"üìã Template: {template}", "generation")
        
        start_time = time.time()
        
        try:
            # Cr√©er le r√©pertoire de travail pour cette ex√©cution
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            project_name = self._extract_project_name(brief)
            run_dir = Path("sandbox/crew_output") / f"{project_name}_{timestamp}"
            run_dir.mkdir(parents=True, exist_ok=True)
            
            # Stocker le r√©pertoire de travail actuel
            self.current_project_folder = run_dir
            
            # LLM d√©j√† assign√©s directement dans _create_agents (pas de routeur)
            info(f"ü§ñ LLM Assign√©s:", "llm")
            info(f"  - Superviseur: openai", "llm")
            info(f"  - D√©veloppeur: ollama", "llm")
            info(f"  - Testeur: ollama", "llm")
            
            # Durcir: s'assurer que run_dir existe syst√©matiquement avant cr√©ation des outils
            self.current_project_folder.mkdir(parents=True, exist_ok=True)
            
            # Cr√©er les tools simplifi√©s
            write_tool = make_write_file_tool(self.current_project_folder)
            
            # Assigner les tools aux agents (tous ont les m√™mes tools simplifi√©s)
            for agent in self.agents.values():
                agent.tools = [write_tool, validate_python_syntax]
            
            # Cr√©er les t√¢ches avec brief inject√©
            tasks = self._create_project_tasks_with_brief(brief, template)
            
            # Cr√©er le crew avec processus s√©quentiel et param√®tres simples
            crew = Crew(
                agents=list(self.agents.values()),
                tasks=tasks,
                process=Process.sequential,
                verbose=True,
                memory=True
            )
            
            # Ex√©cuter la g√©n√©ration
            result = crew.kickoff(inputs={
                "brief": brief,
                "template": template,
                "project_name": self._extract_project_name(brief)
            })
            
            # Analyser les r√©sultats
            execution_time = time.time() - start_time
            generated_files = list(self.current_project_folder.rglob("*")) if self.current_project_folder else {}
            
            return {
                "status": "success",
                "execution_time": round(execution_time, 2),
                "files": {str(f.relative_to(self.current_project_folder)): f.read_text(encoding='utf-8') 
                         for f in generated_files if f.is_file()} if self.current_project_folder else {},
                "agents_count": len(self.agents),
                "tasks_count": len(tasks),
                "result": str(result),
                "output_directory": str(self.current_project_folder)
            }
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration: {e}")
            return {
                "status": "error",
                "error": str(e),
                "execution_time": time.time() - start_time
            }
    
    def _create_project_tasks_with_brief(self, brief: str, template: str) -> List[Task]:
        """Cr√©e les 3 t√¢ches s√©quentielles simplifi√©es avec brief explicitement inject√©"""
        tasks = []
        
        # T√ÇCHE 1: PLANNER (Superviseur) avec brief inject√©
        tasks.append(Task(
            description=(
                "En te basant STRICTEMENT sur ce brief (ne pas inventer autre chose):\n"
                f"'''{brief}'''\n\n"
                "- Produis un plan.json exhaustif: modules, fichiers, interfaces/endpoints, sch√©mas DB, plan de tests.\n"
                "- √âcris directement le fichier 'plan.json' via l'outil write_file_tool.\n"
                "- Utilise le dossier de projet d√©j√† cr√©√© (ne pas cr√©er de nouveau dossier).\n"
                "- Pas de code ici; seulement la structure et les contrats testables."
            ),
            expected_output="Fichier 'plan.json' cr√©√© √† la racine du run_dir.",
            agent=self.agents["supervisor"]
        ))
        
        # T√ÇCHE 2: D√âVELOPPEMENT (D√©veloppeur)
        tasks.append(Task(
            description="Impl√©menter TOUT le code (backend, frontend, API, DB, UI) strictement selon plan.json sans √©cart du contrat.",
            expected_output="Tous les fichiers de code impl√©ment√©s selon plan.json.",
            agent=self.agents["developer"]
        ))
        
        # T√ÇCHE 3: TESTS (Testeur)
        tasks.append(Task(
            description="G√©n√©rer tests Pytest et script smoke-tests ; v√©rifier toutes les fonctionnalit√©s principales.",
            expected_output="tests/*.py, scripts/smoke_test.sh, rapport minimal.",
            agent=self.agents["tester"]
        ))
        
        return tasks
    
    def _extract_project_name(self, brief: str) -> str:
        """Extrait un nom de projet du brief"""
        # Nettoie et extrait les premiers mots significatifs
        words = re.findall(r'\b[a-zA-Z]{3,}\b', brief.lower())
        project_name = "_".join(words[:2]) if len(words) >= 2 else "lunacore_project"
        return project_name

# Instance globale pour utilisation facile
luna_crew = None

def get_crew_system() -> LunaCrewSystem:
    """Retourne l'instance globale du syst√®me CrewAI"""
    global luna_crew
    if luna_crew is None:
        luna_crew = LunaCrewSystem()
    return luna_crew
